# TelecomX_Parte2

---

## ğŸ“Š PredicciÃ³n de CancelaciÃ³n de Clientes en - TelecomX

Este proyecto tiene como objetivo **predecir la cancelaciÃ³n de clientes (churn)** en una empresa de telecomunicaciones(TelecomX), utilizando diferentes algoritmos de Machine Learning y comparando su rendimiento.  

El anÃ¡lisis permite identificar quÃ© clientes estÃ¡n mÃ¡s propensos a cancelar el servicio y quÃ© variables influyen en su decisiÃ³n, ayudando a la empresa a diseÃ±ar estrategias de retenciÃ³n mÃ¡s efectivas.  

---

## ğŸš€ TecnologÃ­as Utilizadas
- **Python 3.10** ğŸ 
- **Google Colab / Jupyter Notebook**
- **Bibliotecas principales**:
  - `pandas` â†’ ManipulaciÃ³n y limpieza de datos.
  - `numpy` â†’ CÃ¡lculos numÃ©ricos.
  - `matplotlib` & `seaborn` â†’ VisualizaciÃ³n de datos.
  - `scikit-learn` â†’ Modelos predictivos y mÃ©tricas de evaluaciÃ³n.

---

## ğŸ“‚ Estructura del Proyecto
- TelecomX_Parte2.ipynb # Notebook principal con el anÃ¡lisis completo

---
  
## ğŸ” Flujo del Proyecto
1. **ExploraciÃ³n y preprocesamiento de datos**:
   - Limpieza de valores nulos y categÃ³ricos.
   - EstandarizaciÃ³n de variables.
   - CodificaciÃ³n de variables categÃ³ricas con *One-Hot Encoding*.

2. **Modelos predictivos utilizados**:
   - **RegresiÃ³n LogÃ­stica**
   - **Random Forest**
  
3. **EvaluaciÃ³n de modelos**:
   - Accuracy, Precision, Recall, F1-Score.
   - Matriz de confusiÃ³n.
   - Importancia de variables (*Random Forest*).

---

## ğŸ“ˆ Resultados Visuales

### ğŸ”¹ ComparaciÃ³n de MÃ©tricas entre Modelos
![ComparaciÃ³n de mÃ©tricas](comparacion_metricas.png)

### ğŸ”¹ Importancia de Variables (Random Forest)
![Importancia de variables](importancia_variables_RF.png)

### ğŸ”¹ Matriz de ConfusiÃ³n - Random Forest
![Matriz de confusiÃ³n RF](matriz_confusion_Random_Forest.png)

### ğŸ”¹ Matriz de ConfusiÃ³n - RegresiÃ³n LogÃ­stica
![Matriz de confusiÃ³n RL](matriz_confusion_Regresion_Logistica.png)

---

## ğŸ”‘ InterpretaciÃ³n de Variables Relevantes

- **RegresiÃ³n LogÃ­stica** â†’ Variables como el tiempo de contrato y el tipo de plan tienen fuerte peso en la cancelaciÃ³n.  
- **Random Forest** â†’ La variable mÃ¡s importante fue el **tipo de contrato**, seguida del **tiempo de antigÃ¼edad del cliente** y **mÃ©todos de pago**.  

---

## ğŸ’¡ Estrategias de RetenciÃ³n Propuestas

1. **FidelizaciÃ³n de clientes con contrato mensual**: ofrecer beneficios por migrar a contratos de mayor permanencia.  
2. **Ofertas personalizadas**: descuentos o paquetes especiales a clientes con alto consumo de datos.  
3. **Mejora en la experiencia de pago**: optimizar mÃ©todos de pago electrÃ³nicos para reducir la fricciÃ³n.  
4. **AtenciÃ³n proactiva**: contactar a clientes en riesgo antes de que cancelen, basÃ¡ndose en las variables mÃ¡s predictivas.  

---

## âœ… Conclusiones

- El modelo de **Random Forest** fue el que **mejor desempeÃ±o obtuvo** con valores superiores en **Accuracy y Recall**, lo que lo convierte en la mejor opciÃ³n para predecir el *churn*.  
- La **RegresiÃ³n LogÃ­stica** mostrÃ³ un desempeÃ±o estable y sencillo de interpretar, siendo Ãºtil como modelo base.  
- La variable con mayor importancia predictiva fue **`tenure (antigÃ¼edad del cliente)`**, seguida de las variables relacionadas con **servicios contratados** y **mÃ©todos de pago**.  
- Estrategias de retenciÃ³n sugeridas:
  - Programas de fidelizaciÃ³n para clientes con menor tiempo en la compaÃ±Ã­a.
  - Ofertas personalizadas segÃºn los servicios contratados.
  - Flexibilidad en mÃ©todos de pago para reducir la fricciÃ³n.
 
---

## ğŸ§‘â€ğŸ’» Autor
ğŸ‘¤ **Andrew Gonzales ZeÃ±a**  
ğŸ“§ [andrew_gz1103@outlook.com](mailto:andrew_gz1103@outlook.com)  
ğŸ’¼ Estudiante de **IngenierÃ­a de Sistemas (UTP)** | **EspecializaciÃ³n en Ciencia de Datos (ALURA LATAM)**
ğŸ“ Lima, PerÃº  

---

## â­ CÃ³mo contribuir
Si quieres mejorar este proyecto:  
1. Haz un fork ğŸ´  
2. Crea una nueva rama `feature/nueva-funcionalidad`  
3. EnvÃ­a un PR ğŸš€  

---

## ğŸ“Œ Nota
Este proyecto es parte de mi proceso de aprendizaje en **Ciencia de Datos** y representa uno de mis primeros proyectos de predicciÃ³n con Machine Learning.














